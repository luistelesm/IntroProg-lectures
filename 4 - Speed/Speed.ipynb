{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Computers](#toc1_)    \n",
    "  - 1.1. [Three important principles](#toc1_1_)    \n",
    "- 2. [Timing and precomputations](#toc2_)    \n",
    "- 3. [Line profilling](#toc3_)    \n",
    "- 4. [List comprehensions are your friend](#toc4_)    \n",
    "- 5. [Generators](#toc5_)    \n",
    "- 6. [Optimizing Numpy](#toc6_)    \n",
    "  - 6.1. [Tip 1: Always use vectorized operations when available](#toc6_1_)    \n",
    "  - 6.2. [Tip 2: Operations are faster on rows than on columns](#toc6_2_)    \n",
    "  - 6.3. [Tip 3: Also use vectorized operations when it is a bit cumbersome](#toc6_3_)    \n",
    "- 7. [Summary](#toc7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn how to time your code and locate its bottlenecks. \n",
    "\n",
    "You will learn how to alleviate such bottlenecks using techniques such as **comprehensions**, **generators** and **vectorization**. \n",
    "\n",
    "You will hear about the fundamental computational costs of mathematical operations and memory management (caching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"axes.grid\":True,\"grid.color\":\"black\",\"grid.alpha\":\"0.25\",\"grid.linestyle\":\"--\"})\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# magics\n",
    "# conda install line_profiler\n",
    "# conda install memory_profiler\n",
    "\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "# local module\n",
    "import needforspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Computers](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent a **computer** in a simplified diagram as:\n",
    "\n",
    "<img src=\"computer.gif\" alt=\"computer\" width=60% />\n",
    "\n",
    "**Performance goals:**\n",
    "\n",
    "1. Minimize the number of logical and algebraic operations ([details](https://streamhpc.com/blog/2012-07-16/how-expensive-is-an-operation-on-a-cpu/))\n",
    "2. Minimize the number of times new memory needs to be allocated (and the amount)\n",
    "3. Minimize the number of read and write memory (and especially storage) operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing your code for **optimal performance is a very very complicated task**. \n",
    "\n",
    "When using Python a lot of stuff is happening *under the hood*, which you don't control. \n",
    "\n",
    "* Python is an **interpreted** language; each line of Python code is converted into machine code at runtime when the line is reached. Error checks and memory management are performed automatically.\n",
    "* Faster languages (C/C++, Fortran) are **compiled** to machine code before the program is run $\\rightarrow$ faster, but you are required to specify e.g. types of variables beforehand. Error checks and memory management must be performed manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Often overlooked**, todays CPUs are so fast that feeding them data quickly enough can be a serious bottleneck."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modern CPUs** can do a lot of smart, complicated, stuff.\n",
    "\n",
    "* **Single-instruction multiply data (SIMD):** The computional cost of multiplying one float with another is the same as multiplying e.g. vectors of 4 doubles at once (or 8 doubles if you have AVX-512).\n",
    "\n",
    "* **Out-of-order execution:** If you tell the computer to\n",
    " \n",
    "    1. read data ``X``\n",
    "    2. run ``f(X)``\n",
    "    3. read data ``Y``\n",
    "    4. run ``g(Y)``\n",
    "\n",
    "    then it might try to do step 2 and step 3 simultanously because they use different parts of the CPU.\n",
    "\n",
    "* **Caching:** Let ``x`` be a one-dimensional numpy array, and assume you read the value in ``x[i]`` and then read the value in ``x[j]``. If ``j`` is \"close\" to ``i`` then the value of ``x[j]`` will already be in the *cache* and the second read operation will be faster (almost instantanous)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallization:** \n",
    "\n",
    "1. Modern computers have multiple CPUs (or even other computing units such as GPUs). \n",
    "2. This is to some degree used implicitely by e.g. built-in Numpy and Scipy functions, but can also be done manually. \n",
    "3. The clock speed of each CPU has stopped increasing for technical reasons, the number of transistors on each chip continue to increase exponentially (**Moore's Law**) due to more CPUs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"moores_law.png\" alt=\"moores_law\" width=80% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory:** We have many different kinds of memory\n",
    "\n",
    "1. Cache\n",
    "2. RAM (Random Access Memory)\n",
    "3. Hard drive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We control what is in the **RAM** and on the the **hard drive**; the latter is a lot slower than the former.\n",
    "<br>The cache is used by the computer under the hood."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"memory.gif\" alt=\"memory\" width=40% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. <a id='toc1_1_'></a>[Three important principles](#toc0_)\n",
    "\n",
    "1. **Use built-in features** of Python, Numpy, Scipy etc. whenever possible (often use fast compiled code).\n",
    "2. **Ordered operations** is better than random operations.\n",
    "3. **\"Premature optimization is the root of all evil\"** (Donald Knuth). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a **trade-off** between **human time** (the time it takes to write the code) and **computer time** (the time it takes to run the code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Timing and precomputations](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following function doing some simple algebraic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun(x,i):\n",
    "    y = 0\n",
    "    for j in range(100):\n",
    "        y += x**j\n",
    "    return y + i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another function calling the former function in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun_loop(n):\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum += myfun(5,i)\n",
    "    return mysum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How long does it take to run ``myfun_loop``:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** Manual timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038064003 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "mysum = myfun_loop(1000)\n",
    "t1 = time.time()    \n",
    "print(f'{t1-t0:.8} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B.** Use the ``%time`` magic (work on a single line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 ms, sys: 661 µs, total: 32.3 ms\n",
      "Wall time: 32 ms\n",
      "CPU times: user 26.6 ms, sys: 41 µs, total: 26.6 ms\n",
      "Wall time: 26.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time mysum = myfun_loop(1000)\n",
    "%time mysum = myfun_loop(1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ms** $\\equiv$ milliseconds, $10^{-3}$ of a second.<br>\n",
    "**$\\mu$ s** $\\equiv$ mikroseconds, $10^{-6}$ of a second.<br>\n",
    "**ns** $\\equiv$ nanoseconds, $10^{-9}$ of a second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.** Use the ``%timeit`` magic to also see variability (work on single line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.2 ms ± 133 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "25.9 ms ± 65.5 µs per loop (mean ± std. dev. of 5 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit myfun_loop(1000)\n",
    "%timeit -r 5 -n 20 myfun_loop(1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``%timeit`` report the best of ``r`` runs each calling the code ``n`` times in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D.** Use the ``%%time`` magic (work on a whole cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 ms, sys: 696 µs, total: 37.5 ms\n",
      "Wall time: 37.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 1000\n",
    "mysum = myfun_loop(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E.** Use the ``%%timeit`` magic to also see variabilty (work on a whole cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.2 ms ± 661 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n = 1000\n",
    "myfun_loop(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How can we speed up the computation using **precomputation**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code\n",
    "    \n",
    "# remember\n",
    "def myfun_loop(n):\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum += myfun(5,i)\n",
    "    return mysum\n",
    "\n",
    "def myfun(x,i):\n",
    "    y = 0\n",
    "    for j in range(100):\n",
    "        y += x**j\n",
    "    return y + i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def myfun_loop_fast(n):\n",
    "    myfunx = myfun(5,0) # precomputation\n",
    "    mysum = 0\n",
    "    for i in range(n):\n",
    "        mysum += myfunx + i\n",
    "    return mysum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00024009 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "mysum_fast = myfun_loop_fast(1000)\n",
    "t1 = time.time()    \n",
    "print(f'{t1-t0:.8f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too fast to be measured with ``time.time()``. The ``%timeit`` magic still works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6 ms ± 189 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "85.7 µs ± 457 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit myfun_loop(1000)\n",
    "%timeit myfun_loop_fast(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rightarrow$ **orders of magnitude faster!**\n",
    "\n",
    "Check the **results are the same**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mysum == mysum_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Line profilling](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Premature optimization is the root of all evil!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:** Before deciding whether to do a precomputation (which often makes the code harder to read) we should investigate, whether it alleviates a bottleneck.\n",
    "\n",
    "* **A.** Insert multiple ``time.time()`` to time different parts of the code.\n",
    "* **B.** Use the ``line_profiler`` with syntax (also works with methods for classes)\n",
    "\n",
    "  ``%lprun -f FUNCTION_TO_PROFILE -f FUNCTION_TO_PROFILE FUNCTION_TO_RUN``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.084795 s\n",
      "File: /var/folders/4y/_xd0t7w55zb75cqtt1fwpt2m0000gq/T/ipykernel_10615/2824044186.py\n",
      "Function: myfun_loop at line 4\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     4                                           def myfun_loop(n):\n",
      "     5         1       1000.0   1000.0      0.0      mysum = 0\n",
      "     6      1001    1195000.0   1193.8      1.4      for i in range(n):\n",
      "     7      1000   83599000.0  83599.0     98.6          mysum += myfun(5,i)\n",
      "     8         1          0.0      0.0      0.0      return mysum\n",
      "\n",
      "Total time: 0.049514 s\n",
      "File: /var/folders/4y/_xd0t7w55zb75cqtt1fwpt2m0000gq/T/ipykernel_10615/2824044186.py\n",
      "Function: myfun at line 10\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    10                                           def myfun(x,i):\n",
      "    11      1000     117000.0    117.0      0.2      y = 0\n",
      "    12    101000   12185000.0    120.6     24.6      for j in range(100):\n",
      "    13    100000   37039000.0    370.4     74.8          y += x**j\n",
      "    14      1000     173000.0    173.0      0.3      return y + i"
     ]
    }
   ],
   "source": [
    "%lprun -f myfun -f myfun_loop myfun_loop(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Most of the time is spend in ``myfun()``, more specifically the computation of the power in line 4. The precomputation solves this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare with the fast method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.000414 s\n",
      "File: /var/folders/4y/_xd0t7w55zb75cqtt1fwpt2m0000gq/T/ipykernel_10615/3913433440.py\n",
      "Function: myfun_loop_fast at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def myfun_loop_fast(n):\n",
      "     2         1      48000.0  48000.0     11.6      myfunx = myfun(5,0) # precomputation\n",
      "     3         1          0.0      0.0      0.0      mysum = 0\n",
      "     4      1001     175000.0    174.8     42.3      for i in range(n):\n",
      "     5      1000     191000.0    191.0     46.1          mysum += myfunx + i\n",
      "     6         1          0.0      0.0      0.0      return mysum"
     ]
    }
   ],
   "source": [
    "%lprun -f myfun_loop_fast myfun_loop_fast(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a id='toc4_'></a>[List comprehensions are your friend](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the first $n$ squares using a **loop**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squares(n):\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(i*i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a **list comprehension**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squares_comprehension(n):\n",
    "    return [i*i for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They give the **same result**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "mylist = squares(n)\n",
    "mylist_fast = squares_comprehension(n)\n",
    "assert mylist == mylist_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the **list comphrension is faster**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.6 µs ± 197 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "37.5 µs ± 280 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mylist = squares(n)\n",
    "%timeit mylist_fast = squares_comprehension(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why is this slower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 µs ± 916 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [i**2 for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a id='toc5_'></a>[Generators](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you are only interested in the **sum of the squares**. Can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_list = [i*i for i in range(n)]\n",
    "mysum = 0\n",
    "for square in squares_list:\n",
    "    mysum += square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** In line 1 we create the full list even though we only need one element at a time<br>\n",
    "$\\rightarrow $ *we allocate memory we need not allocate.*\n",
    "\n",
    "**Solution:** Can be avoided with a **generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares_generator = (i*i for i in range(n)) # notice: parentheses instead of brackets\n",
    "mysum_gen = 0\n",
    "for square in squares_generator:\n",
    "    mysum_gen += square\n",
    "\n",
    "assert mysum == mysum_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **memory footprint** can be investigated with the **memory_profiler** with syntax\n",
    "\n",
    "``%mprun -f FUNCTION_TO_PROFILE -f FUNCTION_TO_PROFILE FUNCTION_TO_RUN``\n",
    "\n",
    "**Caveat:** Needs to be a function in an external module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/luistm/GitHub/IntroProg-lectures/4 - Speed/needforspeed.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     9     33.0 MiB     33.0 MiB           1   def test_memory(n):\n",
      "    10                                         \n",
      "    11                                             # list vs. generators\n",
      "    12     76.2 MiB     43.2 MiB           1       squares = create_list(n)\n",
      "    13     76.2 MiB      0.0 MiB           1       squares_generator = create_generator(n)\n",
      "    14                                         \n",
      "    15                                             # numpy arrays of different types\n",
      "    16     84.3 MiB      8.1 MiB           1       A = np.ones((1000,1000))\n",
      "    17     91.9 MiB      7.7 MiB           1       B = np.ones((1000,1000),dtype=np.double)\n",
      "    18     95.8 MiB      3.8 MiB           1       C = np.ones((1000,1000),dtype=np.single)\n",
      "    19    103.4 MiB      7.7 MiB           1       D = np.ones((1000,1000),dtype=np.int64)\n",
      "    20    107.3 MiB      3.9 MiB           1       E = np.ones((1000,1000),dtype=np.int32)\n",
      "    21    107.4 MiB      0.1 MiB           1       F = np.ones((1000,1000),dtype=np.bool)"
     ]
    }
   ],
   "source": [
    "%mprun -f needforspeed.test_memory needforspeed.test_memory(10**6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **MiB** 1 MiB = 1.048576 MB\n",
    "\n",
    " **Numpy:** Note how you can save memory by specifying the data type for the numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative:** Generators can also be created as functions with a ``yield`` instead of a ``return`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_func(n):\n",
    "    for i in range(n):\n",
    "        yield i*i\n",
    "\n",
    "squares_generator = f_func(n)\n",
    "mysum_gen = 0\n",
    "for square in squares_generator:\n",
    "    mysum_gen += square\n",
    "\n",
    "assert mysum == mysum_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a id='toc6_'></a>[Optimizing Numpy](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. <a id='toc6_1_'></a>[Tip 1: Always use vectorized operations when available](#toc0_)\n",
    "\n",
    "**Simple comparison:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.3 ms ± 1.18 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "113 ms ± 730 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "85.8 µs ± 4.08 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.uniform(size=500000)\n",
    "\n",
    "def python_add(x):\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        y.append(xi+1)\n",
    "    return y\n",
    "\n",
    "def numpy_add(x):\n",
    "    y = np.empty(x.size)\n",
    "    for i in range(x.size):\n",
    "        y[i] = x[i]+1\n",
    "    return y\n",
    "\n",
    "def numpy_add_vec(x):\n",
    "    return x+1\n",
    "\n",
    "assert np.allclose(python_add(x),numpy_add(x))\n",
    "assert np.allclose(python_add(x),numpy_add_vec(x))\n",
    "\n",
    "%timeit python_add(x)\n",
    "%timeit numpy_add(x)\n",
    "%timeit numpy_add_vec(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even **stronger** when the **computation is more complicated:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 ms ± 21.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "621 ms ± 8.67 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "4.45 ms ± 371 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def python_exp(x):\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        y.append(np.exp(xi))\n",
    "    return y\n",
    "\n",
    "def numpy_exp(x):\n",
    "    y = np.empty(x.size)\n",
    "    for i in range(x.size):\n",
    "        y[i] = np.exp(x[i])\n",
    "    return y\n",
    "\n",
    "def numpy_exp_vec(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "assert np.allclose(python_exp(x),numpy_exp(x))\n",
    "assert np.allclose(python_exp(x),numpy_exp_vec(x))\n",
    "\n",
    "%timeit python_exp(x)\n",
    "%timeit numpy_exp(x)\n",
    "%timeit numpy_exp_vec(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also works for a **conditional sum**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 ms ± 6.92 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.61 ms ± 42.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.32 ms ± 45.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def python_exp_cond(x):\n",
    "    return [np.exp(xi) for xi in x if xi < 0.5]\n",
    "\n",
    "def numpy_exp_vec_cond(x):\n",
    "    y = np.exp(x[x < 0.5])\n",
    "    return y\n",
    "\n",
    "def numpy_exp_vec_cond_alt(x):\n",
    "    y = np.exp(x)[x < 0.5]\n",
    "    return y\n",
    "\n",
    "assert np.allclose(python_exp_cond(x),numpy_exp_vec_cond(x))\n",
    "assert np.allclose(python_exp_cond(x),numpy_exp_vec_cond_alt(x))\n",
    "\n",
    "%timeit python_exp_cond(x)\n",
    "%timeit numpy_exp_vec_cond(x)\n",
    "%timeit numpy_exp_vec_cond_alt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do you think the speed-up is less pronounced in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. <a id='toc6_2_'></a>[Tip 2: Operations are faster on rows than on columns](#toc0_)\n",
    "\n",
    "Generally, operate on the **outermost index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6 ms ± 42.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.59 ms ± 132 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "x = np.random.uniform(size=(n,n))\n",
    "\n",
    "def add_rowsums(x):\n",
    "    mysum = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        mysum += np.sum(np.exp(x[i,:]))\n",
    "    return mysum\n",
    "            \n",
    "def add_colsums(x):\n",
    "    mysum = 0\n",
    "    for j in range(x.shape[1]):\n",
    "        mysum += np.sum(np.exp(x[:,j]))\n",
    "    return mysum\n",
    "\n",
    "assert np.allclose(add_rowsums(x),add_colsums(x))\n",
    "            \n",
    "%timeit add_rowsums(x)\n",
    "%timeit add_colsums(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NumEconCopenhagen/lectures-2019/raw/master/11/numpy_memory_layout.png\" alt=\"amdahls_law\" width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **memory structure can be changed manually** so that working on columns (innermost index) is better than working on rows (outermost index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.1 ms ± 1.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "13.7 ms ± 748 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(x,order='F') # the default is order='C'\n",
    "%timeit add_rowsums(y)\n",
    "%timeit add_colsums(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. <a id='toc6_3_'></a>[Tip 3: Also use vectorized operations when it is a bit cumbersome](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the task of calculating the following **expected value**:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W(a)&=\\mathbb{E}\\left[\\sqrt{\\frac{a}{\\psi}+\\xi}\\right]\\\\\n",
    "\\psi,\\xi&\\in \\begin{cases}\n",
    "0.25 & \\text{with prob. }0.25\\\\\n",
    "0.5 & \\text{with prob. }0.25\\\\\n",
    "1.5 & \\text{with prob. }0.25\\\\\n",
    "1.75 & \\text{with prob. }0.25\n",
    "\\end{cases}\\end{aligned}\n",
    "$$\n",
    "\n",
    "for a vector of $a$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "a_vec = np.linspace(0,10,N)\n",
    "\n",
    "xi_vec = np.array([0.25,0.5,1.5,1.75])\n",
    "psi_vec = np.array([0.25,0.5,1.5,1.75])\n",
    "\n",
    "xi_w_vec = np.ones(4)/4\n",
    "psi_w_vec = np.ones(4)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop based solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 ms ± 1.64 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def loop(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec):\n",
    "    \n",
    "    w_vec = np.zeros(a_vec.size)\n",
    "    for i,a in enumerate(a_vec):        \n",
    "        for xi,xi_w in zip(xi_vec,xi_w_vec):\n",
    "            for psi,psi_w in zip(psi_vec,psi_w_vec):\n",
    "                m_plus = a/psi + xi\n",
    "                v_plus = np.sqrt(m_plus)\n",
    "                w_vec[i] += xi_w*psi_w*v_plus\n",
    "    \n",
    "    return w_vec\n",
    "        \n",
    "loop_result = loop(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec)  \n",
    "%timeit loop(a_vec,xi_vec,psi_vec,xi_w_vec,psi_w_vec)      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 µs ± 4.36 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def vec(a,xi,psi,xi_w,psi_w):   \n",
    "    m_plus_vec = a[:,np.newaxis,np.newaxis]/psi[np.newaxis,:,np.newaxis] + xi[np.newaxis,np.newaxis,:]\n",
    "    v_plus_vec = np.sqrt(m_plus_vec)\n",
    "    w_mat = xi_w[np.newaxis,np.newaxis,:]*psi_w[np.newaxis,:,np.newaxis]*v_plus_vec\n",
    "    w_vec = np.sum(w_mat,axis=(1,2))\n",
    "    return w_vec\n",
    "\n",
    "vec_result = vec(a_vec,psi_vec,xi_vec,xi_w_vec,psi_w_vec)\n",
    "assert np.allclose(loop_result,vec_result)\n",
    "%timeit vec(a_vec,psi_vec,xi_vec,xi_w_vec,psi_w_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Much much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <a id='toc7_'></a>[Summary](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that optimizing performance is a difficult task, but the recommendation is to follow the following 4-step procedure:\n",
    "\n",
    "1. Choose the **right algorithm**\n",
    "2. Implement **simple and robust code** for the algorithm \n",
    "3. Profile the code to **find bottlenecks**\n",
    "4. Use **precomputations**, **comphrensions** and **vectorization** to speed-up the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cphcourses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
